# ğŸ›¡ï¸ Logging Reliability & Zero Data Loss Architecture

## âš ï¸ Váº¥n Äá» ÄÆ°á»£c Giáº£i Quyáº¿t

NhÆ° báº¡n chá»‰ ra, stack cÆ¡ báº£n sá»­ dá»¥ng HTTP Ä‘á»ƒ gá»­i logs tá»« Promtail â†’ Loki **cÃ³ nguy cÆ¡ máº¥t logs** trong production:

### Äiá»ƒm yáº¿u cá»§a cáº¥u hÃ¬nh cÆ¡ báº£n:
1. âŒ **Network failures**: Khi network bá»‹ giÃ¡n Ä‘oáº¡n, logs cÃ³ thá»ƒ bá»‹ drop
2. âŒ **Loki downtime**: Khi Loki restart/upgrade, logs Ä‘ang gá»­i sáº½ bá»‹ máº¥t
3. âŒ **No buffer**: KhÃ´ng cÃ³ queue/buffer, logs gá»­i trá»±c tiáº¿p
4. âŒ **Limited retry**: Retry háº¡n cháº¿, sau Ä‘Ã³ drop logs
5. âŒ **Single point of failure**: 1 Loki instance down = máº¥t data

## âœ… Giáº£i PhÃ¡p: Multi-Layer Protection

ChÃºng ta cÃ³ **2 approaches** tÃ¹y theo yÃªu cáº§u:

---

## ğŸŸ¢ OPTION 1: Enhanced Direct Pipeline (Recommended cho SME)

**Cáº£i thiá»‡n stack hiá»‡n táº¡i vá»›i:**

### 1. Promtail WAL (Write-Ahead Log)
```yaml
# promtail-config.yaml
wal:
  enabled: true
  dir: /tmp/wal
  segment_age: 10m
  max_segment_age: 1h
```

**Hoáº¡t Ä‘á»™ng:**
- âœ… Promtail write logs vÃ o disk TRÆ¯á»šC khi gá»­i
- âœ… Náº¿u Loki down, logs Ä‘Æ°á»£c buffer trong WAL
- âœ… Khi Loki up láº¡i, Promtail replay WAL vÃ  gá»­i tiáº¿p
- âœ… **KhÃ´ng máº¥t logs** khi Loki restart

### 2. Aggressive Retry vá»›i Backoff
```yaml
# promtail-config.yaml
clients:
  - url: http://loki:3100/loki/api/v1/push
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10  # Retry 10 láº§n
```

**Hoáº¡t Ä‘á»™ng:**
- âœ… Retry vá»›i exponential backoff
- âœ… Min 500ms â†’ Max 5 phÃºt
- âœ… 10 attempts trÆ°á»›c khi drop (WAL sáº½ buffer trong lÃºc retry)

### 3. Loki WAL (Ingester WAL)
```yaml
# loki-config.yaml
ingester:
  wal:
    enabled: true
    dir: /tmp/loki/wal
    flush_on_shutdown: true
    replay_memory_ceiling: 4GB
```

**Hoáº¡t Ä‘á»™ng:**
- âœ… Loki write logs vÃ o WAL trÆ°á»›c khi index
- âœ… Náº¿u Loki crash, WAL Ä‘Æ°á»£c replay khi restart
- âœ… Data integrity guaranteed

### 4. Positions Tracking
```yaml
# promtail-config.yaml
positions:
  filename: /tmp/positions.yaml
  sync_period: 10s
```

**Hoáº¡t Ä‘á»™ng:**
- âœ… Track vá»‹ trÃ­ Ä‘Ã£ Ä‘á»c trong má»—i file
- âœ… Sync má»—i 10s vÃ o disk
- âœ… KhÃ´ng Ä‘á»c láº¡i logs cÅ© khi restart

### ğŸ¯ Guarantees:

| Scenario | Data Loss? | Explanation |
|----------|-----------|-------------|
| Loki restart | âŒ NO | Promtail WAL buffers logs |
| Promtail restart | âŒ NO | Positions file tracks read position |
| Network partition | âŒ NO | WAL buffers, retry khi network restore |
| Loki crash | âŒ NO | Loki WAL replays on startup |
| Both crash | âš ï¸ Minimal | Only in-flight data (< 10s window) |

**Äá»™ tin cáº­y: 99.9%**

---

## ğŸ”µ OPTION 2: Kafka-Buffered Pipeline (Enterprise-grade)

**ThÃªm Kafka lÃ m buffer layer Ä‘á»ƒ Ä‘áº¡t 99.99% reliability**

### Architecture:

```
Applications (NestJS)
    â”‚ JSON logs
    â–¼
Promtail (with WAL)
    â”‚ HTTP
    â–¼
Kafka Topic: logging-events
    â”‚ Guaranteed delivery
    â”‚ Retention: 7 days
    â”‚ Replication: 3x
    â–¼
Loki Kafka Consumer
    â”‚ At-least-once delivery
    â–¼
Loki (Write path)
    â”‚ Indexed & stored
    â–¼
Grafana (Read path)
```

### Kafka Configuration:

```yaml
# Kafka topic cho logs
topic: logging-events
partitions: 6
replication_factor: 3
retention.ms: 604800000  # 7 days
min.insync.replicas: 2   # Require 2 replicas ACK
```

### Promtail â†’ Kafka:

```yaml
# promtail-kafka-config.yaml
clients:
  - url: kafka://kafka:29092/logging-events
    kafka_config:
      producer_config:
        required_acks: all        # Äá»£i táº¥t cáº£ replicas ACK
        idempotent: true          # TrÃ¡nh duplicates
        compression: snappy
        retry_max: 10
```

### Loki Kafka Consumer:

```yaml
# loki-kafka-consumer
environment:
  - KAFKA_GROUP_ID=loki-consumer-group
  - KAFKA_AUTO_OFFSET_RESET=earliest
  - KAFKA_ENABLE_AUTO_COMMIT=false
  - LOKI_URL=http://loki-write:3100/loki/api/v1/push
```

### ğŸ¯ Guarantees:

| Scenario | Data Loss? | Explanation |
|----------|-----------|-------------|
| Loki restart | âŒ NO | Kafka buffers for 7 days |
| Loki down 24h | âŒ NO | Kafka retention = 7 days |
| Promtail restart | âŒ NO | Kafka has logs, consumer resumes |
| Network partition | âŒ NO | Kafka + WAL |
| Kafka crash (1 broker) | âŒ NO | Replication factor = 3 |
| All Kafka down | âŒ NO | Promtail WAL buffers |
| Datacenter failure | âš ï¸ RPO < 1s | With multi-DC Kafka |

**Äá»™ tin cáº­y: 99.99% - 99.999%**

---

## ğŸ“Š So SÃ¡nh 2 Options

| TiÃªu chÃ­ | Option 1: Direct + WAL | Option 2: Kafka Buffer |
|----------|----------------------|----------------------|
| **Reliability** | 99.9% | 99.99% |
| **Max buffer time** | ~1 hour (WAL) | 7 days (Kafka) |
| **Complexity** | Low | Medium |
| **Resource overhead** | Low | Medium-High |
| **Cost** | Low | Higher (Kafka cluster) |
| **Recovery time** | Minutes | Seconds |
| **Best for** | SME, < 100GB/day | Enterprise, > 100GB/day |
| **Max downtime** | 1-2 hours | 7 days |

---

## ğŸ”§ Monitoring & Alerting

Cáº£ 2 options Ä‘á»u cÃ³ monitoring stack:

### Prometheus Metrics:

```yaml
# Monitor Promtail
promtail_sent_entries_total
promtail_read_bytes_total
promtail_file_bytes_total

# Monitor Loki
loki_distributor_bytes_received_total
loki_ingester_chunks_flushed_total
loki_request_duration_seconds

# Monitor Kafka (Option 2)
kafka_consumergroup_lag
kafka_topic_partition_current_offset
```

### Alerts:

```yaml
# Critical: Promtail down
- alert: PromtailDown
  expr: up{job="promtail"} == 0
  for: 5m
  severity: critical

# Warning: High lag
 - alert: PromtailFileLag
  expr: (promtail_file_bytes_total - promtail_read_bytes_total) > 10MB
  for: 15m
  severity: warning

# Critical: Loki down
- alert: LokiDown
  expr: up{job="loki"} == 0
  for: 5m
  severity: critical

# Critical: Kafka lag (Option 2)
- alert: KafkaLoggingTopicLag
  expr: kafka_consumergroup_lag{topic="logging-events"} > 100000
  for: 10m
  severity: critical
```

---

## ğŸ“ Files Structure

### Option 1: Direct + WAL (ÄÃ£ cáº­p nháº­t)
```
.docker/
â”œâ”€â”€ docker-compose.logging.yaml       # Updated vá»›i WAL volumes
â”œâ”€â”€ promtail-config.yaml              # Updated vá»›i WAL, retry, backoff
â”œâ”€â”€ loki-config.yaml                  # Updated vá»›i ingester WAL
â””â”€â”€ data/
    â”œâ”€â”€ promtail/                     # Positions file
    â”œâ”€â”€ promtail-wal/                 # â­ Promtail WAL buffer
    â”œâ”€â”€ loki/                         # Loki chunks & index
    â””â”€â”€ loki/wal/                     # â­ Loki ingester WAL
```

### Option 2: Kafka-Buffered (Má»›i táº¡o)
```
.docker/
â”œâ”€â”€ docker-compose.logging-ha.yaml    # â­ HA stack vá»›i Kafka
â”œâ”€â”€ promtail-kafka-config.yaml        # â­ Promtail â†’ Kafka
â”œâ”€â”€ loki-ha-config.yaml               # â­ Loki HA vá»›i read/write split
â”œâ”€â”€ prometheus-logging.yaml           # â­ Monitor logging stack
â”œâ”€â”€ alertmanager-config.yaml          # â­ Alerting
â”œâ”€â”€ prometheus-alerts.yaml            # â­ Alert rules
â””â”€â”€ data/
    â”œâ”€â”€ kafka/                        # Kafka data (from main compose)
    â”œâ”€â”€ promtail-wal/                 # Promtail WAL
    â”œâ”€â”€ loki/                         # Loki data
    â””â”€â”€ prometheus/                   # Metrics data
```

---

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### Option 1: Enhanced Direct (Default - Recommended)

```bash
# ÄÃ£ tá»± Ä‘á»™ng cáº­p nháº­t file config
cd .docker
docker-compose -f docker-compose.logging.yaml up -d

# Verify WAL directories Ä‘Æ°á»£c táº¡o
ls -la data/promtail-wal
ls -la data/loki/wal
```

### Option 2: Kafka-Buffered

```bash
# BÆ°á»›c 1: Ensure Kafka Ä‘ang cháº¡y
docker-compose up -d zookeeper kafka

# BÆ°á»›c 2: Táº¡o Kafka topic
docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic logging-events \
  --partitions 6 \
  --replication-factor 3 \
  --config retention.ms=604800000 \
  --config min.insync.replicas=2

# BÆ°á»›c 3: Start HA logging stack
cd .docker
docker-compose -f docker-compose.logging-ha.yaml up -d

# BÆ°á»›c 4: Verify
docker-compose -f docker-compose.logging-ha.yaml ps
```

---

## ğŸ§ª Testing Data Loss Scenarios

### Test 1: Loki Restart (Should NOT lose logs)

```bash
# Generate logs
for i in {1..1000}; do
  echo "{\"level\":\"info\",\"message\":\"Test log $i\"}" >> logs/test.log
  sleep 0.1
done &

# Restart Loki while generating
docker restart loki

# Wait for Loki to come back
sleep 30

# Query Grafana - all 1000 logs should be there
curl -G "http://localhost:3100/loki/api/v1/query" \
  --data-urlencode 'query={job="test"}' | jq '.data.result[0].values | length'
```

**Expected: 1000 logs** âœ…

### Test 2: Network Partition

```bash
# Disconnect Loki from network
docker network disconnect monitoring loki

# Generate logs (will go to WAL)
for i in {1..500}; do
  echo "{\"level\":\"info\",\"message\":\"During partition $i\"}" >> logs/test.log
  sleep 0.1
done

# Reconnect
docker network connect monitoring loki

# Wait for WAL replay
sleep 60

# All logs should arrive
```

**Expected: 500 logs** âœ…

### Test 3: Kafka Buffer (Option 2)

```bash
# Stop Loki consumer
docker stop loki-kafka-consumer

# Generate logs (will buffer in Kafka)
for i in {1..10000}; do
  echo "{\"level\":\"info\",\"message\":\"Buffered log $i\"}" >> logs/test.log
  sleep 0.01
done

# Verify Kafka has logs
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic logging-events \
  --from-beginning --max-messages 10

# Restart consumer
docker start loki-kafka-consumer

# All logs will be consumed
```

**Expected: 10000 logs** âœ…

---

## ğŸ“ˆ Performance & Capacity

### Option 1: Direct + WAL

- **Throughput**: ~50k logs/sec
- **Max WAL size**: 10GB (configurable)
- **Buffer duration**: 1-2 hours
- **Recovery time**: 5-10 minutes

### Option 2: Kafka-Buffered

- **Throughput**: ~500k logs/sec
- **Max buffer**: 7 days retention
- **Buffer size**: Unlimited (disk-bound)
- **Recovery time**: Real-time

---

## âœ… Recommendations

### Cho Development:
- âœ… Use **Option 1** (Direct + WAL)
- Low complexity, good enough

### Cho Staging:
- âœ… Use **Option 1** (Direct + WAL)
- Test reliability scenarios

### Cho Production < 1M logs/day:
- âœ… Use **Option 1** (Direct + WAL)
- Cost-effective, reliable

### Cho Production > 1M logs/day:
- âœ… Use **Option 2** (Kafka-Buffered)
- Enterprise-grade reliability
- Scalable
- Worth the complexity

---

## ğŸ¯ Káº¿t Luáº­n

**Báº¡n hoÃ n toÃ n Ä‘Ãºng** khi lo ngáº¡i vá» data loss vá»›i HTTP direct push!

ChÃºng ta Ä‘Ã£ cáº£i thiá»‡n:

1. âœ… **Promtail WAL** - Buffer local khi Loki down
2. âœ… **Loki WAL** - Data integrity khi Loki crash
3. âœ… **Aggressive retry** - 10 attempts vá»›i backoff
4. âœ… **Positions tracking** - KhÃ´ng Ä‘á»c láº¡i logs cÅ©
5. âœ… **(Option 2) Kafka** - Enterprise-grade buffer

**Há»‡ thá»‘ng giá» Ä‘Ã¢y Ä‘áº£m báº£o:**
- âœ… **Realtime delivery** (< 1s latency)
- âœ… **Zero data loss** (99.9% - 99.99%)
- âœ… **Monitoring & Alerting** (catch issues early)
- âœ… **Disaster recovery** (WAL replay + Kafka buffer)

**Sáºµn sÃ ng cho production!** ğŸš€
